# Pacific Puddle Jump Data Cleaning Project
by: Shane C. 

## Overview
This project aims to enforce my data cleaning/data analytical skills. The project is divided into two main parts, each handled by a separate Jupyter Notebookâ€”`completedClean.ipynb` for the data cleaning phase, and `pacificpuddle.ipynb` for the data analysis phase.

## Technologies Used
- [Python 3](https://www.python.org/downloads/)
- [Jupyter Notebook](https://jupyter.org/install)
- [Pandas](https://pandas.pydata.org/)
- [NumPy](https://numpy.org/)
- [Matplotlib](https://matplotlib.org/)
- [Seaborn](https://seaborn.pydata.org/)

## Description
The primary goal of this project is get creative with functions when extracting cetain content from multiple web pages and open up different methods for cleaning my raw data, then to run statistiics and graphical representations on my data. The project consists of two Jupyter Notebooks focusing on different aspects:

### completedClean.ipynb
- **Input**: Raw data in CSV format
- **Output**: Cleaned data in CSV format
- **Description**: This notebook includes steps required for cleaning the dataset. It serves as the preparatory phase before any analysis can be performed.

### pacificPuddle.ipynb
- **Input**: Cleaned data from `completedClean.ipynb`
- **Output**: Graphs, tables, and other statistical measures
- **Description**: This notebook focuses on analyzing the cleaned data. It includes various data visualization techniques and [other tasks, e.g., machine learning].

## Setup/Installation Requirements
1. Install Python 3 from the [official website](https://www.python.org/downloads/).
2. Install Jupyter Notebook, preferably via Anaconda. Here's a [guide](https://www.datacamp.com/community/tutorials/installing-jupyter-notebook) on how to do it.
3. Install the required Python libraries by running `pip install pandas numpy matplotlib seaborn` in your command line.
4. Clone this repository to your local machine.
5. Navigate to the local repository and run `jupyter notebook` to open the Jupyter Notebook in your browser.
6. Open the notebooks and execute the cells to proceed with data cleaning and analysis.

